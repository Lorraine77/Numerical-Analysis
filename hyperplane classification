### Problem 2
## part a
A <- matrix(runif(4,100,900),2)
B <- matrix(runif(4,-9,9),2)
C <- matrix(runif(4,-900,-100),2)
Z <- matrix(0,2,2)
M <- cbind(rbind(Z,Z,C),rbind(Z,B,Z),rbind(A,Z,Z))
# M
# [,1]      [,2]      [,3]     [,4]     [,5]     [,6]
# [1,]    0.000    0.0000  0.000000 0.000000 524.6614 103.1420
# [2,]    0.000    0.0000  0.000000 0.000000 415.0704 802.8948
# [3,]    0.000    0.0000 -2.254062 6.933359   0.0000   0.0000
# [4,]    0.000    0.0000 -8.025516 6.204437   0.0000   0.0000
# [5,] -101.105 -399.8822  0.000000 0.000000   0.0000   0.0000
# [6,] -736.045 -328.3799  0.000000 0.000000   0.0000   0.0000

# to get u,s and v 
u <- svd(M)$u
d <- svd(M)$d
s <- diag(d)
v <- svd(M)$v

M_new <- u%*%s%*%t(v)
# > M_new
# [,1]          [,2]          [,3]          [,4]          [,5]
# [1,]  2.677137e-14 -4.346220e-14  2.502882e-15 -4.586958e-15  5.246614e+02
# [2,]  0.000000e+00  0.000000e+00 -1.231057e-15  1.640654e-15  4.150704e+02
# [3,]  0.000000e+00  0.000000e+00 -2.254062e+00  6.933359e+00  3.651547e-14
# [4,]  0.000000e+00  0.000000e+00 -8.025516e+00  6.204437e+00  0.000000e+00
# [5,] -1.011050e+02 -3.998822e+02 -4.569126e-31  7.798418e-31 -1.584089e-13
# [6,] -7.360450e+02 -3.283799e+02  2.617351e-31 -5.575360e-31  6.713306e-14
# [,6]
#[1,]  1.031420e+02
#[2,]  8.028948e+02
#[3,] -1.645807e-13
#[4,]  0.000000e+00
#[5,] -1.003885e-13
#[6,]  1.677854e-14

# M_new is almost the same as the M, except for round-off errors, looks good.

## part b
# write a function to compute M_k, where k is the dimension of the reduced M
M_k <- function(u,s,v,k)
{ n <- dim(M)[1]
  M_k <- matrix(0,n,n)
  for (i in 1:k)
  {
    M_k <- M_k+s[i,i]*u[,i]%*%t(v[,i])
    
  }
  return(M_k)
}

#M_k when k=1
# > M_k(u,s,v,1)
#       [,1] [,2] [,3] [,4]          [,5]          [,6]
# [1,]    0    0    0    0  2.442055e+02  3.183077e+02
# [2,]    0    0    0    0  5.415408e+02  7.058668e+02
# [3,]    0    0    0    0 -6.595349e-14 -8.596652e-14
# [4,]    0    0    0    0  0.000000e+00  0.000000e+00
# [5,]    0    0    0    0 -1.071744e-13 -1.396956e-13
# [6,]    0    0    0    0  3.297674e-14  4.298326e-14

# M_k when k=2
#> M_k(u,s,v,2)
#           [,1]   [,2]  [,3] [,4]         [,5]          [,6]
#[1,]    0.0000    0.0000    0    0  2.442055e+02  3.183077e+02
#[2,]    0.0000    0.0000    0    0  5.415408e+02  7.058668e+02
#[3,]    0.0000    0.0000    0    0 -6.595349e-14 -8.596652e-14
#[4,]    0.0000    0.0000    0    0  0.000000e+00  0.000000e+00
#[5,] -251.8599 -155.1379    0    0 -1.071744e-13 -1.396956e-13
#[6,] -680.2267 -418.9986    0    0  3.297674e-14  4.298326e-14

# M_k when k=3
# > M_k(u,s,v,3)
#         [,1]      [,2] [,3] [,4]          [,5]          [,6]
#[1,]    0.0000    0.0000    0    0  5.246614e+02  1.031420e+02
#[2,]    0.0000    0.0000    0    0  4.150704e+02  8.028948e+02
#[3,]    0.0000    0.0000    0    0  3.651547e-14 -1.645807e-13
#[4,]    0.0000    0.0000    0    0  0.000000e+00  0.000000e+00
#[5,] -251.8599 -155.1379    0    0 -1.584089e-13 -1.003885e-13
#[6,] -680.2267 -418.9986    0    0  6.713306e-14  1.677854e-14

# M_k when k=4
> M_k(u,s,v,4)
#              [,1]          [,2] [,3] [,4]          [,5]          [,6]
# [1,]  2.677137e-14 -4.346220e-14    0    0  5.246614e+02  1.031420e+02
# [2,]  0.000000e+00  0.000000e+00    0    0  4.150704e+02  8.028948e+02
# [3,]  0.000000e+00  0.000000e+00    0    0  3.651547e-14 -1.645807e-13
# [4,]  0.000000e+00  0.000000e+00    0    0  0.000000e+00  0.000000e+00
# [5,] -1.011050e+02 -3.998822e+02    0    0 -1.584089e-13 -1.003885e-13
# [6,] -7.360450e+02 -3.283799e+02    0    0  6.713306e-14  1.677854e-14

# M_k when k=5
# > M_k(u,s,v,5)
#               [,1]          [,2]          [,3]          [,4]          [,5]
# [1,]  2.677137e-14 -4.346220e-14  3.363678e-15 -3.831207e-15  5.246614e+02
# [2,]  0.000000e+00  0.000000e+00 -1.349299e-15  1.536842e-15  4.150704e+02
# [3,]  0.000000e+00  0.000000e+00 -4.418702e+00  5.032873e+00  3.651547e-14
# [4,]  0.000000e+00  0.000000e+00 -6.569577e+00  7.482705e+00  0.000000e+00
# [5,] -1.011050e+02 -3.998822e+02 -5.855325e-31  6.669177e-31 -1.584089e-13
# [6,] -7.360450e+02 -3.283799e+02  3.903550e-31 -4.446118e-31  6.713306e-14
# [,6]
# [1,]  1.031420e+02
# [2,]  8.028948e+02
# [3,] -1.645807e-13
# [4,]  0.000000e+00
# [5,] -1.003885e-13
# [6,]  1.677854e-14

# M_k when k=6
#              [,1]          [,2]          [,3]          [,4]          [,5]
#[1,]  2.677137e-14 -4.346220e-14  2.502882e-15 -4.586958e-15  5.246614e+02
#[2,]  0.000000e+00  0.000000e+00 -1.231057e-15  1.640654e-15  4.150704e+02
#[3,]  0.000000e+00  0.000000e+00 -2.254062e+00  6.933359e+00  3.651547e-14
#[4,]  0.000000e+00  0.000000e+00 -8.025516e+00  6.204437e+00  0.000000e+00
#[5,] -1.011050e+02 -3.998822e+02 -4.569126e-31  7.798418e-31 -1.584089e-13
#[6,] -7.360450e+02 -3.283799e+02  2.617351e-31 -5.575360e-31  6.713306e-14
#[,6]
#[1,]  1.031420e+02
#[2,]  8.028948e+02
#[3,] -1.645807e-13
#[4,]  0.000000e+00
#[5,] -1.003885e-13
#[6,]  1.677854e-14

# when k= 6, M_k and M are very close. therefore we can reduce M to 6 dimensional


## part c


### Prob 3
require(Matrix)
mydata<- read.table("C:/Users/Administrator/Desktop/user-shows.txt")
shows <- read.table("C:/Users/Administrator/Desktop/shows.txt")
shows <- as.matrix(shows)
alex_real <- read.table("C:/Users/Administrator/Desktop/alex.txt", quote="\"")
alex_real <- as.numeric(alex_real)
M <- as.matrix(mydata)
alex_est <- as.numeric(M[500,])
# there are 563 shows and 9985 users, the columns of matrix M represent different
# shows, and the rows of M represent different users
# so u corresponds to people and v correspond to shows

u <- svd(M)$u
v <- svd(M)$v
d <- svd(M)$d
s <- diag(d)



# first try to reduce the dimension to 2
# 2-dimensional case
u1 <- u[,1:2]
v1 <- v[,1:2]
d1 <- d[1:2]
s1 <- diag(d1)

# the reduced new matrix is 
M_1 <- u1%*%s1%*%t(v1)



#plot the users
# since the two colums of u1 represent different types of users
users <- Matrix(0,nrow(u),nrow(u),sparse=T)
diag(users) <- 1
type_1 <- t(u)%*%users[1,]
type_2 <- t(u)%*%users[2,]

plot(type_1,type_2)

#plot the shows
shows <- Matrix(0,nrow(v),nrow(v),sparse=T)
diag(shows) <- 1
type_1 <- t(v)%*%shows[1,]
type_2 <- t(v)%*%shows[2,]
plot(type_1,type_2)

# to see the how they match Alex¡¯s the real preference
#project alex onto span consists of colums of v1

c <- t(v1)%*%alex_est
proj <-v1%*%c
max5<- sort(proj[1:100],decreasing=T)[1:5]
opt_choices<- c()
for(i in 1:5){
  opt_choices[i] <- which(proj[1:100]==max5[i])
}


alex_real[opt_choices]
# > alex_real[opt_choices]
# [1] 0 1 1 0 0
# we can see that only two estimates match alex's real prefernce

# We should try other dimensions
# I dicidedto write a function to compute the correctness of estimate
# whose input is the value of dimension
estimate <- function(m)
{
  u_new <- u[,1:m]
  v_new <- v[,1:m]
  d_new <- d[1:m]
  s_new <- diag(d_new)
  c <- t(v_new)%*%alex_est
  proj <-v_new%*%c
  max5<- sort(proj[1:100],decreasing=T)[1:5]
  opt_choices<- c()
  for(i in 1:5){
    opt_choices[i] <- which(proj[1:100]==max5[i])
  }
  
  # only when alex(opt_choices)=(1,1,1,1,1) we find the best reduced dimension
  # so when defind the correctness sum(alex_real[opt_choices), when its value is 5
  # we find the best answer
  
  correctness <- sum(alex_real[opt_choices])
  
  return(list(correctness=correctness,dimension=m))
}

j<- 1
correctness <- estimate(1)$correctness
while (correctness<5)
{ 
  j <- j+1
  correctness <- estimate(j)$correctness
}
# > correctness
# [1] 5
# > j
# [1] 8
# therefore k=8 should be the optimal dimension that we should reduce M to



##Prob 4

iris <- read.table("C:/Users/Administrator/Desktop/iris.txt",sep=',')
iris_pca = as.matrix(iris[,1:4])

##Part a
myPCA=function(D,n=2){
  cov_D=cov(D)
  e_vec=eigen(cov_D)$vectors
  proj=D%*%e_vec[,1:n]
  
  return(list(eig_cov=e_vec,proj_n=proj))   
}

proj_iris=myPCA(as.matrix(iris[,1:4]),2)$proj_n
pch_iris=rep(0,length(iris[,1]))
pch_iris[iris[,5]==-1]=20
plot(proj_iris,pch=pch_iris,main='my PCA iris')



#ii

# Use PCA R function to  plot the data points in the 2 dimensional space
pca_value = princomp(iris_pca)
pc_new = as.matrix(pca_value$loadings[,1:2])
plot(iris_pca%*%pc_new,pch = ifelse(proj_iris[,1]<4,20,0),main='R inside function')


## Part b
# the dimension reduction does separate the points according to their classes, plot seen in part apch_iris=rep(1,length(iris[,1]))


## Part c
# Use the function to find  separating hyperplane in HW6
# to compute a hyperplane for the iris data
x=iris[,1:4]
y=iris[,5]
beta=runif(5,-1,1)

#first filter the data points that are misclassified.
filter=function(beta){
  mis=c()
  for (i in 1:nrow(iris)){
    mis[i]=y[i]*(beta[5]+sum(beta[1:4]*x[i,]))
  }
  y_e=y[mis<0]
  x_e=x[mis<0,]
  mis_e=mis[mis<0]
  return(list(x_error=x_e,y_error=y_e,mis_error=mis_e))
}
filter(beta)

# function for error
error=function(beta){
  f=-sum(filter(beta)$mis_error)
  return(f)
}
error(beta)

grad=function(beta){
  #for the points that land on the hyperplane, the gradient doesn't exist. we can ignore these data points
  #and see what to do with these data later. because I guess there will not be many data points landing on
  #the hyperplane.
  x_error=filter(beta)$x_error
  y_error=filter(beta)$y_error
  g=c()
  g[5]=sum(y_error)
  for (j in 1:4){
    g[j]=-sum(x_error[,j]*y_error)
  }
  return(g)
}
grad(beta)


## Part c
re_error=function(beta){
  y_error=filter(beta)$y_error
  a=length(y_error)/length(y)
  return(a)
}
re_error(beta)

steepest_hyper=function(beta,eps1,eps2){
  g=grad(beta)
  gnorm=sqrt(sum(g^2))
  i=0
  while(gnorm>=eps1 | re_error(beta)>=eps2){
    d=-g/gnorm
    alpha=1
    while(abs(error(beta+alpha*d))>=abs(error(beta))){
      alpha=alpha/2
    }
    beta=beta+alpha*d
    g=grad(beta)
    gnorm=sqrt(sum(g^2))
    
    
    i=i+1
    # print(i)
  }
  return(beta)
}

beta_hyper=steepest_hyper(beta,0.1,0.1)
# > beta_hyper
# [1]  0.08769917 -0.26415072 -0.11501251  1.09937935 -0.40275968

re_error(beta_hyper)
# [1] 0
# re_error=o means that it's the seperating plane
# it takes very short time to compute this seperating plane

## Part d
# the hyperplane is sum(beta[1:4]*x)+beta[5]=0
# the coefficients of x is consist of the vector orthogonal to the plane, so 

u= beta_hyper[1:4]

# choose an arbitrary vector q in the plane, which satisfies the equation of the plane

q=runif(3)
q[4]=(-beta_hyper[5]-sum(beta_hyper[1:3]*q))/beta_hyper[4] 


proj_hyper=as.matrix(iris[,1:4])%*%qr.Q(qr(cbind(u,q)))

par(mfrow=c(1,2))
plot(proj_hyper,pch=pch_iris,main='my pca hyperplane')
plot(proj_iris,pch=pch_iris,main='my PCA iris')
plot(iris_pca%*%pc_new,pch = ifelse(proj_iris[,1]<4,20,0), main = "R inside function")

# the projection with two different methods are different in the same plane





